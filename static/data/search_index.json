[
  {
    "type": "notepad",
    "id": "file_automation",
    "title": "File Operations Automation",
    "description": "A simple script to automate file operations on your system. Demonstrates safe directory creation and file copying.",
    "content": "#!/usr/bin/env python3\n\"\"\"\nA simple script to demonstrate file operations automation.\nThis script shows how to work with directories and files safely.\n\"\"\"\n\nimport os\nimport shutil\nfrom pathlib import Path\n\ndef setup_directories():\n    \"\"\"Create necessary directories for file operations.\"\"\"\n    base_path = Path(\"./workspace\")\n    \n    try:\n        base_path.mkdir(exist_ok=True)\n        print(f\"Directory created: {base_path}\")\n    except FileExistsError:\n        print(f\"Directory already exists: {base_path}\")\n    \n    return base_path\n\ndef copy_files(source_dir, dest_dir):\n    \"\"\"Copy files from source to destination directory.\"\"\"\n    source = Path(source_dir)\n    destination = Path(dest_dir)\n    \n    if not source.exists():\n        print(f\"Source directory {source} does not exist\")\n        return\n    \n    try:\n        destination.mkdir(parents=True, exist_ok=True)\n        \n        for file_path in source.glob(\"*.txt\"):\n            dest_file = destination / file_path.name\n            shutil.copy2(file_path, dest_file)\n            print(f\"Copied: {file_path.name}\")\n            \n    except Exception as e:\n        print(f\"Error copying files: {e}\")\n\ndef main():\n    \"\"\"Main function to orchestrate file operations.\"\"\"\n    print(\"Starting file automation script...\")\n    \n    # Setup workspace\n    workspace = setup_directories()\n    \n    # Example file operations\n    print(\"File operations completed successfully!\")\n\nif __name__ == \"__main__\":\n    main()",
    "tags": [
      "automation",
      "files",
      "beginner"
    ],
    "filePath": "scripts/script_a.py",
    "url": "/notepads/file_automation"
  },
  {
    "type": "notepad",
    "id": "data_analysis_utils",
    "title": "Data Analysis Utilities for Pandas",
    "description": "Helper functions for data manipulation and cleaning using Pandas. Includes trend analysis, outlier filtering, and data export capabilities.",
    "content": "\"\"\"\nData Analysis Utilities for Pandas\n\nHelper functions for data manipulation and cleaning using Pandas.\nProvides common operations for data preprocessing and analysis.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, List, Dict, Any\n\ndef clean_data(df: pd.DataFrame, \n               drop_nulls: bool = True,\n               fill_value: Optional[Any] = None) -> pd.DataFrame:\n    \"\"\"\n    Clean a pandas DataFrame by handling missing values and duplicates.\n    \n    Args:\n        df: Input DataFrame to clean\n        drop_nulls: Whether to drop rows with null values\n        fill_value: Value to fill nulls with (if drop_nulls is False)\n    \n    Returns:\n        Cleaned DataFrame\n    \"\"\"\n    cleaned_df = df.copy()\n    \n    # Remove duplicates\n    cleaned_df = cleaned_df.drop_duplicates()\n    \n    # Handle missing values\n    if drop_nulls:\n        cleaned_df = cleaned_df.dropna()\n    elif fill_value is not None:\n        cleaned_df = cleaned_df.fillna(fill_value)\n    \n    return cleaned_df\n\ndef analyze_trends(df: pd.DataFrame, \n                  date_column: str,\n                  value_column: str) -> Dict[str, Any]:\n    \"\"\"\n    Analyze trends in time series data.\n    \n    Args:\n        df: DataFrame with time series data\n        date_column: Name of the date column\n        value_column: Name of the value column to analyze\n    \n    Returns:\n        Dictionary with trend analysis results\n    \"\"\"\n    # Ensure date column is datetime\n    df[date_column] = pd.to_datetime(df[date_column])\n    \n    # Sort by date\n    df_sorted = df.sort_values(date_column)\n    \n    # Calculate basic statistics\n    results = {\n        'mean': df_sorted[value_column].mean(),\n        'median': df_sorted[value_column].median(),\n        'std': df_sorted[value_column].std(),\n        'min': df_sorted[value_column].min(),\n        'max': df_sorted[value_column].max(),\n        'trend': 'increasing' if df_sorted[value_column].iloc[-1] > df_sorted[value_column].iloc[0] else 'decreasing'\n    }\n    \n    return results\n\ndef export_summary(df: pd.DataFrame, filename: str) -> None:\n    \"\"\"\n    Export DataFrame summary statistics to CSV.\n    \n    Args:\n        df: DataFrame to summarize\n        filename: Output filename for the summary\n    \"\"\"\n    summary = df.describe()\n    summary.to_csv(filename)\n    print(f\"Summary exported to {filename}\")\n\ndef filter_outliers(df: pd.DataFrame, \n                   column: str,\n                   method: str = 'iqr') -> pd.DataFrame:\n    \"\"\"\n    Filter outliers from a DataFrame column.\n    \n    Args:\n        df: Input DataFrame\n        column: Column name to filter outliers from\n        method: Method to use ('iqr' or 'zscore')\n    \n    Returns:\n        DataFrame with outliers removed\n    \"\"\"\n    if method == 'iqr':\n        Q1 = df[column].quantile(0.25)\n        Q3 = df[column].quantile(0.75)\n        IQR = Q3 - Q1\n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        \n        return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n    \n    elif method == 'zscore':\n        z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())\n        return df[z_scores < 3]\n    \n    else:\n        raise ValueError(\"Method must be 'iqr' or 'zscore'\")",
    "tags": [
      "data science",
      "pandas",
      "intermediate"
    ],
    "filePath": "scripts/project_x/util.py",
    "url": "/notepads/data_analysis_utils"
  },
  {
    "type": "readme",
    "title": "README - project_x",
    "description": "README file for project_x directory",
    "content": "# Project X - Data Analysis Utilities\n\nThis project contains utility functions for data manipulation and cleaning using Pandas.\n\n## Overview\n\nThe utilities in this project help with:\n- Data cleaning and preprocessing\n- Statistical analysis\n- Data visualization helpers\n- Export/import functionality\n\n## Files\n\n- `util.py` - Main utility functions\n- `data/` - Sample data files for testing\n\n## Usage\n\n```python\nfrom util import clean_data, analyze_trends\n\n# Clean your dataset\ncleaned_data = clean_data(raw_data)\n\n# Analyze trends\nresults = analyze_trends(cleaned_data)\n```\n\n## Dependencies\n\n- pandas\n- numpy\n- matplotlib (optional, for visualization)",
    "filePath": "scripts\\project_x\\README.md",
    "url": "/browser/project_x"
  },
  {
    "type": "markdown",
    "title": "README.md",
    "description": "markdown file in project_x",
    "content": "# Project X - Data Analysis Utilities\n\nThis project contains utility functions for data manipulation and cleaning using Pandas.\n\n## Overview\n\nThe utilities in this project help with:\n- Data cleaning and preprocessing\n- Statistical analysis\n- Data visualization helpers\n- Export/import functionality\n\n## Files\n\n- `util.py` - Main utility functions\n- `data/` - Sample data files for testing\n\n## Usage\n\n```python\nfrom util import clean_data, analyze_trends\n\n# Clean your dataset\ncleaned_data = clean_data(raw_data)\n\n# Analyze trends\nresults = analyze_trends(cleaned_data)\n```\n\n## Dependencies\n\n- pandas\n- numpy\n- matplotlib (optional, for visualization)",
    "filePath": "scripts\\project_x\\README.md",
    "url": "/browser/project_x/README.md"
  },
  {
    "type": "python",
    "title": "util.py",
    "description": "python file in project_x",
    "content": "\"\"\"\nData Analysis Utilities for Pandas\n\nHelper functions for data manipulation and cleaning using Pandas.\nProvides common operations for data preprocessing and analysis.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, List, Dict, Any\n\ndef clean_data(df: pd.DataFrame, \n               drop_nulls: bool = True,\n               fill_value: Optional[Any] = None) -> pd.DataFrame:\n    \"\"\"\n    Clean a pandas DataFrame by handling missing values and duplicates.\n    \n    Args:\n        df: Input DataFrame to clean\n        drop_nulls: Whether to drop rows with null values\n        fill_value: Value to fill nulls with (if drop_nulls is False)\n    \n    Returns:\n        Cleaned DataFrame\n    \"\"\"\n    cleaned_df = df.copy()\n    \n    # Remove duplicates\n    cleaned_df = cleaned_df.drop_duplicates()\n    \n    # Handle missing values\n    if drop_nulls:\n        cleaned_df = cleaned_df.dropna()\n    elif fill_value is not None:\n        cleaned_df = cleaned_df.fillna(fill_value)\n    \n    return cleaned_df\n\ndef analyze_trends(df: pd.DataFrame, \n                  date_column: str,\n                  value_column: str) -> Dict[str, Any]:\n    \"\"\"\n    Analyze trends in time series data.\n    \n    Args:\n        df: DataFrame with time series data\n        date_column: Name of the date column\n        value_column: Name of the value column to analyze\n    \n    Returns:\n        Dictionary with trend analysis results\n    \"\"\"\n    # Ensure date column is datetime\n    df[date_column] = pd.to_datetime(df[date_column])\n    \n    # Sort by date\n    df_sorted = df.sort_values(date_column)\n    \n    # Calculate basic statistics\n    results = {\n        'mean': df_sorted[value_column].mean(),\n        'median': df_sorted[value_column].median(),\n        'std': df_sorted[value_column].std(),\n        'min': df_sorted[value_column].min(),\n        'max': df_sorted[value_column].max(),\n        'trend': 'increasing' if df_sorted[value_column].iloc[-1] > df_sorted[value_column].iloc[0] else 'decreasing'\n    }\n    \n    return results\n\ndef export_summary(df: pd.DataFrame, filename: str) -> None:\n    \"\"\"\n    Export DataFrame summary statistics to CSV.\n    \n    Args:\n        df: DataFrame to summarize\n        filename: Output filename for the summary\n    \"\"\"\n    summary = df.describe()\n    summary.to_csv(filename)\n    print(f\"Summary exported to {filename}\")\n\ndef filter_outliers(df: pd.DataFrame, \n                   column: str,\n                   method: str = 'iqr') -> pd.DataFrame:\n    \"\"\"\n    Filter outliers from a DataFrame column.\n    \n    Args:\n        df: Input DataFrame\n        column: Column name to filter outliers from\n        method: Method to use ('iqr' or 'zscore')\n    \n    Returns:\n        DataFrame with outliers removed\n    \"\"\"\n    if method == 'iqr':\n        Q1 = df[column].quantile(0.25)\n        Q3 = df[column].quantile(0.75)\n        IQR = Q3 - Q1\n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        \n        return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n    \n    elif method == 'zscore':\n        z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())\n        return df[z_scores < 3]\n    \n    else:\n        raise ValueError(\"Method must be 'iqr' or 'zscore'\")",
    "filePath": "scripts\\project_x\\util.py",
    "url": "/browser/project_x/util.py"
  },
  {
    "type": "python",
    "title": "script_a.py",
    "description": "python file in scripts",
    "content": "#!/usr/bin/env python3\n\"\"\"\nA simple script to demonstrate file operations automation.\nThis script shows how to work with directories and files safely.\n\"\"\"\n\nimport os\nimport shutil\nfrom pathlib import Path\n\ndef setup_directories():\n    \"\"\"Create necessary directories for file operations.\"\"\"\n    base_path = Path(\"./workspace\")\n    \n    try:\n        base_path.mkdir(exist_ok=True)\n        print(f\"Directory created: {base_path}\")\n    except FileExistsError:\n        print(f\"Directory already exists: {base_path}\")\n    \n    return base_path\n\ndef copy_files(source_dir, dest_dir):\n    \"\"\"Copy files from source to destination directory.\"\"\"\n    source = Path(source_dir)\n    destination = Path(dest_dir)\n    \n    if not source.exists():\n        print(f\"Source directory {source} does not exist\")\n        return\n    \n    try:\n        destination.mkdir(parents=True, exist_ok=True)\n        \n        for file_path in source.glob(\"*.txt\"):\n            dest_file = destination / file_path.name\n            shutil.copy2(file_path, dest_file)\n            print(f\"Copied: {file_path.name}\")\n            \n    except Exception as e:\n        print(f\"Error copying files: {e}\")\n\ndef main():\n    \"\"\"Main function to orchestrate file operations.\"\"\"\n    print(\"Starting file automation script...\")\n    \n    # Setup workspace\n    workspace = setup_directories()\n    \n    # Example file operations\n    print(\"File operations completed successfully!\")\n\nif __name__ == \"__main__\":\n    main()",
    "filePath": "scripts\\script_a.py",
    "url": "/browser/script_a.py"
  },
  {
    "type": "markdown",
    "title": "script_a_README.md",
    "description": "markdown file in scripts",
    "content": "# File Operations Automation\n\nA beginner-friendly Python script that demonstrates safe file and directory operations using modern Python best practices.\n\n## 📋 Overview\n\nThis script showcases fundamental file system operations that are commonly needed in automation tasks:\n- Creating directories safely\n- Copying files with error handling\n- Using `pathlib` for cross-platform path handling\n- Implementing proper exception handling\n\n## 🎯 Key Features\n\n- **Safe Directory Creation**: Uses `exist_ok=True` to avoid errors when directories already exist\n- **Cross-Platform Compatibility**: Leverages `pathlib.Path` for OS-independent path handling\n- **Error Handling**: Comprehensive try-catch blocks for robust operation\n- **Modern Python**: Uses Python 3.6+ features and best practices\n\n## 🔧 Functions Breakdown\n\n### `setup_directories()`\nCreates a workspace directory in the current location.\n\n**Key Points:**\n- Uses `Path(\"./workspace\")` for relative path creation\n- `mkdir(exist_ok=True)` prevents FileExistsError\n- Returns the created path for further use\n\n### `copy_files(source_dir, dest_dir)`\nCopies all `.txt` files from source to destination directory.\n\n**Features:**\n- Validates source directory exists before proceeding\n- Creates destination directory if it doesn't exist\n- Uses `shutil.copy2()` to preserve file metadata\n- Provides feedback on copied files\n\n### `main()`\nOrchestrates the file operations workflow.\n\n**Purpose:**\n- Entry point for the script\n- Demonstrates function composition\n- Provides user feedback\n\n## 💡 Learning Objectives\n\nAfter studying this script, you'll understand:\n\n1. **Modern Path Handling**\n   ```python\n   # Old way (avoid)\n   import os\n   path = os.path.join(\"folder\", \"file.txt\")\n   \n   # New way (recommended)\n   from pathlib import Path\n   path = Path(\"folder\") / \"file.txt\"\n   ```\n\n2. **Safe Directory Operations**\n   ```python\n   # This won't crash if directory exists\n   path.mkdir(exist_ok=True)\n   \n   # For nested directories\n   path.mkdir(parents=True, exist_ok=True)\n   ```\n\n3. **Exception Handling Best Practices**\n   ```python\n   try:\n       # Risky operation\n       operation()\n   except SpecificError as e:\n       # Handle specific error\n       print(f\"Error: {e}\")\n   ```\n\n## 🚀 Usage Examples\n\n### Basic Usage\n```bash\npython script_a.py\n```\n\n### Customizing the Script\nYou can modify the script for your needs:\n\n```python\n# Change workspace location\nbase_path = Path(\"./my_custom_workspace\")\n\n# Copy different file types\nfor file_path in source.glob(\"*.pdf\"):  # Copy PDF files instead\n    # ... copy logic\n```\n\n## 🔍 Common Use Cases\n\nThis pattern is useful for:\n- **Log File Management**: Organizing log files by date/type\n- **Backup Operations**: Creating backup copies of important files\n- **Data Processing**: Moving processed files to different folders\n- **Project Setup**: Creating standard directory structures\n\n## ⚠️ Important Notes\n\n- Always test file operations with sample data first\n- Be careful with file paths containing spaces or special characters\n- Consider using absolute paths for production scripts\n- Add logging for better debugging in complex scenarios\n\n## 🔗 Related Concepts\n\n- **File I/O in Python**: `open()`, `read()`, `write()`\n- **Advanced Path Operations**: `glob()`, `iterdir()`, `resolve()`\n- **Error Handling**: `try/except/finally`, custom exceptions\n- **Command Line Arguments**: `argparse` for script parameters\n\n## 📚 Next Steps\n\nTo extend this script, consider:\n1. Adding command-line argument parsing\n2. Implementing file filtering by date/size\n3. Adding progress bars for large operations\n4. Creating configuration files for settings\n5. Adding unit tests for reliability\n\n## 🏷️ Tags\n`automation` `files` `beginner` `pathlib` `error-handling`",
    "filePath": "scripts\\script_a_README.md",
    "url": "/browser/script_a_README.md"
  }
]